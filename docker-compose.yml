---
# ----------------------------------------------------------------------------------------
# -- Docs: https://github.com/cluster-apps-on-docker/spark-standalone-cluster-on-docker --
# ----------------------------------------------------------------------------------------
version: "3.6"
volumes:
    shared-workspace:
        name: "hadoop-distributed-file-system"
        driver: local

services:
    airflow:
      build: ./airflow
      ports:
        - 8088:8080
      environment:   
        - FERNET_KEY="bCH80KIHfj-_UAt1b4gaFPJvQCMF73FQRFJGtOhFA-M="
      volumes:
        - ./dags/:/usr/local/airflow/dags
        - ./scripts/:/usr/local/scripts
        
    namenode:
        image: bde2020/hadoop-namenode:1.1.0-hadoop2.8-java8
        container_name: namenode
        volumes:
            - ./data/namenode:/hadoop/dfs/name
        environment:
            - CLUSTER_NAME=test
        env_file:
            - ./hadoop.env
        ports:
            - 9870:50070
            - 9000:9000

    datanode:
        image: bde2020/hadoop-datanode:1.1.0-hadoop2.8-java8
        depends_on: 
            - namenode
        volumes:
            - ./data/datanode:/hadoop/dfs/data
        env_file:
            - ./hadoop.env
        ports:
            - 9875:50075

    hue:
        image: bde2020/hdfs-filebrowser:3.11
        ports:
            - 8089:8088
        environment:
            - NAMENODE_HOST=namenode

    spark-master:
        image: andreper/spark-master:3.0.0
        container_name: spark-master
        ports:
            - 8080:8080
            - 7077:7077
        volumes:
            - shared-workspace:/opt/workspace
        env_file:
            - ./hadoop.env

    spark-worker-1:
        image: andreper/spark-worker:3.0.0
        container_name: spark-worker-1
        environment:
            - SPARK_WORKER_CORES=1
            - SPARK_WORKER_MEMORY=1024m
        ports:
            - 8081:8081
        volumes:
            - shared-workspace:/opt/workspace
        depends_on:
            - spark-master
        env_file:
            - ./hadoop.env

    spark-worker-2:
        image: andreper/spark-worker:3.0.0
        container_name: spark-worker-2
        environment:
            - SPARK_WORKER_CORES=1
            - SPARK_WORKER_MEMORY=1024m
        ports:
            - 8082:8081
        volumes:
            - shared-workspace:/opt/workspace
        depends_on:
            - spark-master
        env_file:
            - ./hadoop.env

    jupyterlab:
        image: andreper/jupyterlab:3.0.0-spark-3.0.0
        container_name: jupyterlab
        ports:
          - 8890:8888
          - 4040:4040
        volumes:
          - shared-workspace:/opt/workspace